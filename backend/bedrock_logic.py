import boto3
import json
import os
import requests
import re
from bs4 import BeautifulSoup
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from typing import Optional, Dict, Any
from sqlalchemy.orm import Session
from datetime import datetime

# --- ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë“ˆ ì„í¬íŠ¸ ---
from backend.routes.ai_challenge_router import AICallengeCreateRequest, create_and_join_ai_challenge
from backend.routes.dashboard import get_dashboard
from backend import schemas
from backend.models import User, TransportMode
from backend.database import get_db

# --- ì„¤ì • ---
# âœ… ì‚¬ìš©ìê°€ ì œê³µí•œ ì„¤ì •ì„ ì—¬ê¸°ì— ë°˜ì˜í•©ë‹ˆë‹¤.
AWS_DEFAULT_REGION = "us-east-1"
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "AIzaSyBgs37kJYWB7zsTfIrDTqe1hpOxBhNkH44")
GOOGLE_CSE_ID = os.getenv("GOOGLE_CSE_ID", "01354cc88406341ec")

# ì¼ë°˜ LLM í˜¸ì¶œì— ì‚¬ìš©í•  ëª¨ë¸ ARN (Inference Profile)
BEDROCK_MODEL_ARN = os.getenv("BEDROCK_MODEL_ARN", "arn:aws:bedrock:us-east-1:327784329358:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0")
# Bedrock ì§€ì‹ ê¸°ë°˜(Knowledge Base) ì„¤ì •
BEDROCK_KNOWLEDGE_BASE_ID = os.getenv("BEDROCK_KNOWLEDGE_BASE_ID", "PUGB1AL6L1")
# ì§€ì‹ ê¸°ë°˜ ë‹µë³€ ìƒì„±ì— ì‚¬ìš©í•  í‘œì¤€ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ ID
BEDROCK_KB_GENERATOR_MODEL_ID = "anthropic.claude-3-sonnet-v1:0"


# --- Boto3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
try:
    bedrock_runtime_client = boto3.client('bedrock-runtime', region_name=AWS_DEFAULT_REGION)
    bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime', region_name=AWS_DEFAULT_REGION)
    print("[ì•Œë¦¼] AWS Bedrock í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"[ì˜¤ë¥˜] AWS í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    bedrock_runtime_client = None
    bedrock_agent_runtime_client = None

# FastAPI ë¼ìš°í„° ìƒì„±
router = APIRouter(
    prefix="/chat",
    tags=["Chatbot"]
)

class ChatRequest(BaseModel):
    user_id: int
    message: str

class RouterDecision(BaseModel):
    action: str
    query: Optional[str] = None
    user_intent: Optional[str] = None
    answer: Optional[str] = None
    dashboard_field: Optional[str] = None

def invoke_llm(system_prompt: str, user_prompt: str) -> Optional[str]:
    """AWS Bedrock LLM í˜¸ì¶œ í•¨ìˆ˜"""
    if not bedrock_runtime_client:
        raise ConnectionError("Bedrock runtime client is not initialized.")
    try:
        messages = [{"role": "user", "content": user_prompt}]
        request_body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 4096,
            "system": system_prompt,
            "messages": messages
        }
        response = bedrock_runtime_client.invoke_model(
            modelId=BEDROCK_MODEL_ARN, # âœ… ì œê³µëœ ARNì„ modelIdë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            body=json.dumps(request_body)
        )
        response_body = json.loads(response.get('body').read())
        return response_body['content'][0]['text']
    except Exception as e:
        print(f"[ì˜¤ë¥˜] Bedrock ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

def query_knowledge_base(query: str) -> Optional[str]:
    """Bedrock ì§€ì‹ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜"""
    if not bedrock_agent_runtime_client or not BEDROCK_KNOWLEDGE_BASE_ID:
        print("[ì•Œë¦¼] ì§€ì‹ ê¸°ë°˜ í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    print(f"\n[ì•Œë¦¼] Bedrock ì§€ì‹ ê¸°ë°˜ì—ì„œ '{query}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    try:
        # ì§€ì‹ ê¸°ë°˜ APIëŠ” í‘œì¤€ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ ARNì´ í•„ìš”í•©ë‹ˆë‹¤.
        model_arn = f"arn:aws:bedrock:{AWS_DEFAULT_REGION}::foundation-model/{BEDROCK_KB_GENERATOR_MODEL_ID}"
        response = bedrock_agent_runtime_client.retrieve_and_generate(
            input={'text': query},
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': BEDROCK_KNOWLEDGE_BASE_ID,
                    'modelArn': model_arn
                }
            }
        )
        if response and response.get('output') and response.get('citations'):
            answer = response['output']['text']
            citations = response['citations']
            source_details = []
            for citation in citations:
                if citation.get('retrievedReferences'):
                    retrieved_ref = citation['retrievedReferences'][0]
                    location = retrieved_ref.get('location', {}).get('s3Location', {}).get('uri')
                    if location:
                        source_details.append(f"- {location}")
            formatted_answer = f"{answer}\n\n--- ì¶œì²˜ ---\n" + "\n".join(source_details) if source_details else answer
            print("[ì•Œë¦¼] ì§€ì‹ ê¸°ë°˜ì—ì„œ ë‹µë³€ì„ ì„±ê³µì ìœ¼ë¡œ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return formatted_answer
        else:
            print("[ì•Œë¦¼] ì§€ì‹ ê¸°ë°˜ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"[ì˜¤ë¥˜] Bedrock ì§€ì‹ ê¸°ë°˜ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

def perform_web_search(query: str) -> str:
    """Google Custom Search APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰"""
    if not GOOGLE_API_KEY or not GOOGLE_CSE_ID:
        return "ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ì™€ CSE IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
    print(f"\n[ì•Œë¦¼] ì›¹ì—ì„œ '{query}'ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    try:
        search_url = "https://www.googleapis.com/customsearch/v1"
        search_params = {'key': GOOGLE_API_KEY, 'cx': GOOGLE_CSE_ID, 'q': query, 'num': 3}
        search_response = requests.get(search_url, params=search_params, timeout=5)
        search_response.raise_for_status()
        search_results = search_response.json().get('items', [])
        
        if not search_results:
            return "ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        snippets = [item.get('snippet', '') for item in search_results]
        return "\n\n".join(snippets)

    except requests.exceptions.RequestException as e:
        print(f"[ì˜¤ë¥˜] ì›¹ ê²€ìƒ‰ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return "ì •ë³´ ê²€ìƒ‰ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

async def _handle_dashboard_query(
    user_id: int, 
    db: Session, 
    router_decision: RouterDecision
) -> str:
    """ëŒ€ì‹œë³´ë“œ ê´€ë ¨ ì¿¼ë¦¬ ì²˜ë¦¬"""
    print("[ì•Œë¦¼] ì‚¬ìš©ì ëŒ€ì‹œë³´ë“œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
    try:
        current_user_obj = db.query(User).filter(User.user_id == user_id).first()
        if not current_user_obj:
            raise HTTPException(status_code=404, detail="User not found")
        
        dashboard_data = await get_dashboard(current_user=current_user_obj, db=db)
        
        field = router_decision.dashboard_field
        if field == "credits":
            return f"í˜„ì¬ ë³´ìœ í•˜ì‹  í¬ë ˆë”§ì€ {dashboard_data.total_points:,}Cì…ë‹ˆë‹¤."
        elif field == "carbon_saved":
            return f"ì§€ê¸ˆê¹Œì§€ ì´ {dashboard_data.total_saved:.2f}kgì˜ íƒ„ì†Œë¥¼ ì ˆì•½í•˜ì…¨ìŠµë‹ˆë‹¤! ì •ë§ ëŒ€ë‹¨í•´ìš”! ğŸŒ±"
        elif field == "garden_level":
            return f"í˜„ì¬ ì •ì› ë ˆë²¨ì€ {dashboard_data.garden_level}ë ˆë²¨ì…ë‹ˆë‹¤. ê³„ì† ë…¸ë ¥í•˜ì‹œë©´ ë” ë©‹ì§„ ì •ì›ì„ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”!"
        elif field == "today_saved":
            return f"ì˜¤ëŠ˜ ì ˆì•½í•˜ì‹  íƒ„ì†ŒëŠ” {dashboard_data.co2_saved_today:.0f}gì…ë‹ˆë‹¤."
        elif field == "recent_activity":
            if dashboard_data.last7days:
                total_saved_7days = sum(d.saved_g for d in dashboard_data.last7days)
                return f"ìµœê·¼ 7ì¼ê°„ ì´ {total_saved_7days:.0f}gì˜ íƒ„ì†Œë¥¼ ì ˆì•½í•˜ì…¨ìŠµë‹ˆë‹¤."
            return "ìµœê·¼ í™œë™ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ë¶€í„° ì‹œì‘í•´ë³´ì„¸ìš”!"
        else:
            challenge_goal = dashboard_data.challenge.goal
            challenge_progress = dashboard_data.challenge.progress
            percentage = (challenge_progress / challenge_goal * 100) if challenge_goal > 0 else 0
            
            return (
                f"ğŸ“Š {current_user_obj.username}ë‹˜ì˜ ëŒ€ì‹œë³´ë“œ ìš”ì•½\n\n"
                f"ğŸ’° ë³´ìœ  í¬ë ˆë”§: {dashboard_data.total_points:,}C\n"
                f"ğŸŒ ì´ ì ˆì•½ íƒ„ì†Œ: {dashboard_data.total_saved:.2f}kg\n"
                f"ğŸŒ³ ì •ì› ë ˆë²¨: {dashboard_data.garden_level}ë ˆë²¨\n"
                f"ğŸ“… ì˜¤ëŠ˜ ì ˆì•½: {dashboard_data.co2_saved_today:.0f}g\n"
                f"ğŸ† ì±Œë¦°ì§€ ì§„í–‰ë¥ : {percentage:.1f}%\n\n"
                "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"
            )
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ëŒ€ì‹œë³´ë“œ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì‚¬ìš©ì ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

async def _handle_recommend_challenge(
    user_query: str, 
    user_id: int, 
    db: Session, 
    router_decision: RouterDecision
) -> str:
    """AI ì±Œë¦°ì§€ ì¶”ì²œ ë° ìƒì„± ë¡œì§"""
    print("[ì•Œë¦¼] AI ì±Œë¦°ì§€ë¥¼ ì¶”ì²œí•˜ê³  ìƒì„±í•©ë‹ˆë‹¤.")
    
    current_user_obj = db.query(User).filter(User.user_id == user_id).first()
    if not current_user_obj:
        raise HTTPException(status_code=404, detail="User not found")
    
    dashboard_data = await get_dashboard(current_user=current_user_obj, db=db)
    
    mode_stats = {m.mode: m.saved_g for m in dashboard_data.modeStats}
    most_used_mode = max(mode_stats, key=mode_stats.get) if mode_stats else "ì—†ìŒ"
    
    challenge_prompt = f"""You are an AI assistant that generates personalized eco-friendly challenges in Korean. Generate ONE challenge that is achievable within 7 days.
    User Stats:
    - Total carbon saved: {dashboard_data.total_saved:.2f}kg
    - Most used transport: {most_used_mode}
    - Garden level: {dashboard_data.garden_level}
    - Recent 7 days activity: {sum(d.saved_g for d in dashboard_data.last7days)}g saved
    
    Create a fun and encouraging challenge. Provide a response ONLY in the following JSON format:
    {{
        "title": "A creative and friendly Korean title",
        "description": "An encouraging Korean description",
        "reward": an integer between 10 and 100,
        "target_mode": "WALK/BIKE/BUS/SUBWAY/ANY",
        "goal_type": "CO2_SAVED/DISTANCE_KM/TRIP_COUNT",
        "goal_target_value": a float or integer
    }}"""
    
    user_intent = router_decision.user_intent or user_query
    challenge_idea_str = invoke_llm(challenge_prompt, f"User intent: {user_intent}")
    
    try:
        json_match = re.search(r'\{.*\}', challenge_idea_str, re.DOTALL)
        if not json_match:
            raise ValueError("LLM ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        challenge_idea = json.loads(json_match.group())
        
        challenge_request = AICallengeCreateRequest(
            title=challenge_idea["title"],
            description=challenge_idea["description"],
            reward=challenge_idea["reward"],
            target_mode=TransportMode[challenge_idea.get("target_mode", "ANY").upper()],
            goal_type=schemas.ChallengeGoalType[challenge_idea["goal_type"].upper()],
            goal_target_value=float(challenge_idea["goal_target_value"])
        )
        
        await create_and_join_ai_challenge(
            request=challenge_request, db=db, current_user=current_user_obj
        )
        
        goal_unit = 'km' if 'DISTANCE' in challenge_idea['goal_type'] else 'g' if 'CO2' in challenge_idea['goal_type'] else 'íšŒ'
        return (
            f"ğŸ¯ ìƒˆë¡œìš´ ì±Œë¦°ì§€ë¥¼ ìƒì„±í–ˆì–´ìš”!\n\n"
            f"**{challenge_idea['title']}**\n"
            f"{challenge_idea['description']}\n\n"
            f"ğŸ ë³´ìƒ: {challenge_idea['reward']}C\n"
            f"ğŸ“Š ëª©í‘œ: {challenge_idea['goal_target_value']} {goal_unit}\n\n"
            f"í™”ì´íŒ…! ë‹¹ì‹ ì˜ ì‘ì€ ì‹¤ì²œì´ ì§€êµ¬ë¥¼ ì‚´ë¦½ë‹ˆë‹¤! ğŸ’š"
        )
        
    except (json.JSONDecodeError, KeyError, ValueError) as e:
        print(f"[ì˜¤ë¥˜] ì±Œë¦°ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\nLLM Raw Response: {challenge_idea_str}")
        return "ì±Œë¦°ì§€ë¥¼ ì¶”ì²œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. ëŒ€ì‹  'ì´ë²ˆ ì£¼ ëŒ€ì¤‘êµí†µ 3ë²ˆ ì´ìš©í•˜ê¸°'ëŠ” ì–´ë– ì„¸ìš”?"

def classify_user_intent(user_query: str) -> RouterDecision:
    """ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” í–¥ìƒëœ í•¨ìˆ˜"""
    router_system_prompt = """You are a highly intelligent routing agent for 'RePlanet', an eco-friendly service application. Your primary role is to accurately classify the user's intent based on their query and provide a structured JSON output. Analyze the user's message carefully and choose the most appropriate action.

Categories and Logic:

1.  **"get_user_dashboard"**: This is for any query related to the user's personal data and statistics within the app.
    * **Keywords (Korean)**: í¬ë ˆë”§, í¬ì¸íŠ¸, íƒ„ì†Œ, ì ˆì•½, ì •ì›, ë ˆë²¨, ë‚´ ì •ë³´, ì–¼ë§ˆë‚˜, ë­í–ˆì§€, ê¸°ë¡, ë°ì´í„°, í˜„í™©, ë“±ê¸‰
    * **Logic**: If the user asks about their own achievements, savings, or status, this is the correct action.
    * **`dashboard_field`**: You MUST populate this field.
        * `credits`: For questions about points, credits (e.g., "ë‚´ í¬ì¸íŠ¸ ì–¼ë§ˆì•¼?").
        * `carbon_saved`: For questions about total carbon savings (e.g., "íƒ„ì†Œ ì–¼ë§ˆë‚˜ ì¤„ì˜€ì–´?").
        * `garden_level`: For questions about their garden's level or status (e.g., "ë‚´ ì •ì› ë ˆë²¨ì€?").
        * `today_saved`: For questions about today's activity (e.g., "ì˜¤ëŠ˜ ë‚´ê°€ í•œ í™œë™ ì•Œë ¤ì¤˜").
        * `recent_activity`: For questions about recent activities or the past week (e.g., "ìµœê·¼ ì¼ì£¼ì¼ ê¸°ë¡ ë³´ì—¬ì¤˜").
        * `all`: For general or multiple data requests (e.g., "ë‚´ ì •ë³´ ìš”ì•½í•´ì¤˜").

2.  **"recommend_challenge"**: This is for when the user wants a new task, mission, or challenge.
    * **Keywords (Korean)**: ì±Œë¦°ì§€, ì¶”ì²œ, ë¯¸ì…˜, í€˜ìŠ¤íŠ¸, í• ë§Œí•œ ê±°, ë­í• ê¹Œ, ë„ì „
    * **Logic**: If the user is looking for a new goal or activity to participate in, use this action.

3.  **"knowledge_base_search"**: This is for questions about the RePlanet service itself, its features, or related environmental policies. This is an internal information search.
    * **Keywords (Korean)**: ë¦¬í”Œë˜ë‹›, ì‚¬ìš©ë²•, ì •ì±…, ì—ì½”ë§ˆì¼ë¦¬ì§€, í¬ì¸íŠ¸ ì‚¬ìš©ë²•, ì•± ê¸°ëŠ¥
    * **Logic**: Questions that can be answered by an FAQ or a user manual fall into this category.
    * **`query`**: Refine the user's question into a clear search term. Example: "í¬ì¸íŠ¸ëŠ” ì–´ë””ë‹¤ ì“¸ ìˆ˜ ìˆì–´?" -> "í¬ì¸íŠ¸ ì‚¬ìš©ì²˜".

4.  **"general_search"**: This is for real-time information, current events, or general knowledge questions not related to the user's data or the app's features. This requires an external web search.
    * **Keywords (Korean)**: ë‚ ì”¨, ì˜¤ëŠ˜, ë‰´ìŠ¤, ìµœì‹ , [ì¼ë°˜ ëª…ì‚¬] ë­ì•¼?, [ì§€ì—­] ì •ë³´
    * **Logic**: If the question cannot be answered by the app's internal data (dashboard, knowledge base), use this.
    * **`query`**: Refine the query for an effective web search. Example: "ì˜¤ëŠ˜ ì„œìš¸ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?" -> "ì„œìš¸ ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ë†ë„".

5.  **"direct_answer"**: This is for simple conversational turns like greetings, thanks, or affirmations where a direct, simple response is sufficient.
    * **Keywords (Korean)**: ì•ˆë…•, í•˜ì´, ê³ ë§ˆì›Œ, ì‘, ì•„ë‹ˆ, ã…‹ã…‹, ã…ã…
    * **Logic**: Use for chit-chat that doesn't fit other categories.
    * **`answer`**: Provide a friendly and short response in Korean.

Output Format: You must respond ONLY with a valid JSON object. Do not include any text before or after the JSON block.

{
    "action": "The selected category name from the list above",
    "query": "A refined search query for 'knowledge_base_search' or 'general_search', otherwise null",
    "user_intent": "The user's original, unmodified message",
    "dashboard_field": "The specific data field for 'get_user_dashboard', otherwise null",
    "answer": "A direct, short response for 'direct_answer', otherwise null"
}
"""
    
    llm_response = invoke_llm(router_system_prompt, user_query)
    
    if not llm_response:
        return RouterDecision(action="general_search", query=user_query, user_intent=user_query)
    
    try:
        json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
        if not json_match:
            raise ValueError("No JSON found in LLM response for router")
            
        decision_data = json.loads(json_match.group())
        decision_data.setdefault("user_intent", user_query)
        return RouterDecision(**decision_data)
    except (json.JSONDecodeError, ValueError) as e:
        print(f"[ì˜¤ë¥˜] ë¼ìš°í„° ê²°ì • íŒŒì‹± ì‹¤íŒ¨: {e}\nLLM Raw Response: {llm_response}")
        return RouterDecision(action="general_search", query=user_query, user_intent=user_query)

@router.post("/")
async def chatbot_endpoint(request: ChatRequest, db: Session = Depends(get_db)) -> Dict[str, Any]:
    """ë©”ì¸ ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸"""
    user_query = request.message
    user_id = request.user_id
    
    current_user_obj = db.query(User).filter(User.user_id == user_id).first()
    if not current_user_obj:
        raise HTTPException(status_code=404, detail="User not found")
    
    print(f"\n{'='*50}\nì‚¬ìš©ì ì§ˆë¬¸: {user_query} (ID: {user_id})\n{'='*50}\n")
    
    router_decision = classify_user_intent(user_query)
    action = router_decision.action
    print(f"[ë¼ìš°í„° ê²°ì •] Action: {action}, Field: {router_decision.dashboard_field}")
    
    final_answer = ""
    
    try:
        if action == "get_user_dashboard":
            final_answer = await _handle_dashboard_query(user_id, db, router_decision)
        elif action == "recommend_challenge":
            final_answer = await _handle_recommend_challenge(user_query, user_id, db, router_decision)
        elif action == "knowledge_base_search":
            final_answer = query_knowledge_base(router_decision.query or user_query)
            if not final_answer:
                action = "general_search"
                print("[ëŒ€ì²´] ì§€ì‹ ê¸°ë°˜ ê²€ìƒ‰ ì‹¤íŒ¨, ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        
        if action == "general_search":
            search_results = perform_web_search(router_decision.query or user_query)
            summarize_prompt = "You are a helpful assistant. Summarize the following search results in Korean concisely and in a friendly tone, directly answering the user's question."
            final_answer = invoke_llm(summarize_prompt, f"User question: {user_query}\n\nSearch results:\n{search_results}")
                
        elif action == "direct_answer":
            final_answer = router_decision.answer or "ì•ˆë…•í•˜ì„¸ìš”! ë¦¬í”Œë˜ë‹› AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š"
        
        if not final_answer:
            final_answer = "ì£„ì†¡í•©ë‹ˆë‹¤, ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”?"
        
        print(f"\n[ìµœì¢… ë‹µë³€]\n{final_answer[:200]}...")
        
        return {
            "response": final_answer,
            "metadata": {
                "action": action,
                "user_id": user_id,
                "timestamp": datetime.utcnow().isoformat()
            }
        }
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail="ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")